{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders\n",
    "\n",
    "In this tutorial, we want to use PyBlaze to train a variational autoencoder (VAE). More precisely, we want to generate handwritten digits as obtained from the MNIST dataset.\n",
    "\n",
    "Later on, we will repeat the same tutorial and train a Wasserstein GAN instead of a VAE.\n",
    "\n",
    "**_Note: This tutorial currently lacks both explanation and any theory. It will be added in the future._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pyblaze.nn as xnn\n",
    "import pyblaze.nn.functional as X\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "At first, we want to load the data. Again, `torchvision` can make our life easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/Downloads/\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/Downloads/\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did before, we can also easily initialize the data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_val_dataset.random_split(0.8, 0.2)\n",
    "train_loader = train_dataset.loader(batch_size=256, num_workers=4, shuffle=True)\n",
    "val_loader = val_dataset.loader(batch_size=2048)\n",
    "test_loader = test_dataset.loader(batch_size=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue to set up our model, we first have a look at a few randomly sampled images from our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "\n",
    "images = [train_dataset[i] for i in np.random.choice(len(train_dataset), 10)]\n",
    "for i, (image, _) in enumerate(images):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(image[0], cmap='binary')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "After we had a look at the data, we can define our model. We use convolutional layers in the encoder and scale the hidden representation up in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(576, 16)\n",
    "        self.fc_logvar = nn.Linear(576, 16)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.conv(x)\n",
    "        z = z.view(z.size(0), -1)\n",
    "        return self.fc_mu(z), self.fc_logvar(z)\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(16, 2048)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 5, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 6)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.fc(x)\n",
    "        z = z.view(-1, 128, 4, 4)\n",
    "        return self.conv(z)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        std = (0.5 * logvar).exp()\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the model, we can initialize it. Let's also see how big it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "\n",
    "print(f'Total parameters:   {sum(p.numel() for p in model.parameters()):6,}')\n",
    "print(f'Encoder parameters: {sum(p.numel() for p in model.encoder.parameters()):6,}')\n",
    "print(f'Decoder parameters: {sum(p.numel() for p in model.decoder.parameters()):6,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "loss = xnn.VAELoss(nn.BCEWithLogitsLoss(reduction='none'))\n",
    "engine = xnn.AutoencoderEngine(model, expects_data_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = engine.train(\n",
    "    train_loader,\n",
    "    val_data=val_loader,\n",
    "    epochs=50,\n",
    "    eval_every=5,\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    callbacks=[\n",
    "        xnn.BatchProgressLogger()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent, var = model.encoder(it[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(it[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.sigmoid().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(np.concatenate([it[0][i][0].numpy(), out[i].reshape(28, 28)]), cmap='binary')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = D.Normal(torch.zeros(16), torch.ones(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = dist.sample((100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.decoder(f).sigmoid().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(out[i].reshape(28, 28), cmap='binary')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Linear(32, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
